{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EaCMipzgw2E7"
      ],
      "authorship_tag": "ABX9TyOIO4qid5x3Gj25AWlnfT/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Iftitahyr/Klasifikasi-Penyakit-Daun-Kopi-Menggunakan-Metode-Machine-Learning-Klasik-dan-CNN/blob/main/split_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**kode program untuk split dataset**"
      ],
      "metadata": {
        "id": "EaCMipzgw2E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urd4YAAcwzly",
        "outputId": "5d9925c6-7ff8-48e8-ee07-d5f6f731aca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91-878K_eu1K",
        "outputId": "460be503-fab0-47ca-a57e-c911c55c00cb"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Mounting Google Drive ---\n",
            "Mounted at /content/drive\n",
            "\n",
            "Original Dataset Path: /content/drive/MyDrive/semester 7/ML Teori/Dataset/Dataset_Daun_Kopi_Balanced\n",
            "Output Split Path: /content/drive/MyDrive/semester 7/ML Teori/Dataset/dataset_coffee_split\n",
            "\n",
            "--- Starting Dataset Splitting Process (80% Train, 10% Validation, 10% Test) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4500 files [03:41, 20.34 files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset split completed successfully!\n",
            "New split dataset is located at: /content/drive/MyDrive/semester 7/ML Teori/Dataset/dataset_coffee_split\n",
            "You will find 'train', 'val', and 'test' subfolders inside.\n",
            "\n",
            "--- Verifying Split Structure and Counts ---\n",
            "Classes found: ['Daun_Bercak', 'Daun_Karat', 'Daun_Sehat']\n",
            "  Daun_Bercak:\n",
            "    Train: 1200 images\n",
            "    Validation: 150 images\n",
            "    Test: 150 images\n",
            "  Daun_Karat:\n",
            "    Train: 1200 images\n",
            "    Validation: 150 images\n",
            "    Test: 150 images\n",
            "  Daun_Sehat:\n",
            "    Train: 1200 images\n",
            "    Validation: 150 images\n",
            "    Test: 150 images\n",
            "\n",
            "--- Overall Split Summary ---\n",
            "Total images in Original Dataset: 4500\n",
            "Total images in Split Dataset (Train + Val + Test): 4500\n",
            "Train Set: 3600 images (80.0%)\n",
            "Validation Set: 450 images (10.0%)\n",
            "Test Set: 450 images (10.0%)\n",
            "Verification: Total images in split dataset matches original dataset.\n",
            "\n",
            "--- Dataset Splitting Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import splitfolders # Pastikan library ini sudah terinstal\n",
        "\n",
        "# ============================================\n",
        "# 1. Mount Google Drive\n",
        "# ============================================\n",
        "print(\"--- Mounting Google Drive ---\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ============================================\n",
        "# 2. Konfigurasi Path Dataset\n",
        "# ============================================\n",
        "# --- PENTING: Sesuaikan path ini dengan lokasi dataset asli Anda di Drive ---\n",
        "# Ini adalah folder yang berisi sub-folder untuk setiap kelas gambar (misal: coffee___healthy, coffee___red_spider_mite, coffee___rust)\n",
        "original_dataset_path = '/content/drive/MyDrive/semester 7/ML Teori/Dataset/Dataset_Daun_Kopi_Balanced'\n",
        "\n",
        "# Ini adalah folder baru tempat dataset yang sudah di-split akan disimpan.\n",
        "# Di dalamnya akan ada sub-folder 'train', 'val', 'test'.\n",
        "output_split_path = '/content/drive/MyDrive/semester 7/ML Teori/Dataset/dataset_coffee_split'\n",
        "\n",
        "print(f\"\\nOriginal Dataset Path: {original_dataset_path}\")\n",
        "print(f\"Output Split Path: {output_split_path}\")\n",
        "\n",
        "# ============================================\n",
        "# 3. Validasi Path dan Persiapan Output Folder\n",
        "# ============================================\n",
        "if not os.path.exists(original_dataset_path):\n",
        "    print(f\"Error: Original dataset path '{original_dataset_path}' not found.\")\n",
        "    print(\"Please check the path and ensure your dataset is located there.\")\n",
        "    exit()\n",
        "\n",
        "# Hapus folder output_split_path jika sudah ada untuk memastikan split yang bersih\n",
        "if os.path.exists(output_split_path):\n",
        "    print(f\"Warning: Existing output directory '{output_split_path}' found.\")\n",
        "    print(\"Deleting existing directory to perform a clean split...\")\n",
        "    try:\n",
        "        shutil.rmtree(output_split_path)\n",
        "        print(\"Existing output directory deleted successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error deleting existing output directory: {e}\")\n",
        "        print(\"Please delete it manually if this persists.\")\n",
        "        exit()\n",
        "\n",
        "# ============================================\n",
        "# 4. Melakukan Pembagian Dataset (Split)\n",
        "# ============================================\n",
        "print(\"\\n--- Starting Dataset Splitting Process (80% Train, 10% Validation, 10% Test) ---\")\n",
        "\n",
        "# Rasio split: (train, validation, test)\n",
        "# 0.8 untuk training, 0.1 untuk validation, 0.1 untuk test\n",
        "split_ratio = (0.8, 0.1, 0.1)\n",
        "random_seed = 42 # Untuk hasil split yang reproduktif\n",
        "\n",
        "try:\n",
        "    splitfolders.ratio(\n",
        "        original_dataset_path,\n",
        "        output=output_split_path,\n",
        "        seed=random_seed,\n",
        "        ratio=split_ratio,\n",
        "        group_prefix=None, # Jangan tambahkan prefix ke nama file\n",
        "        move=False # Penting: Salin file, jangan pindahkan (dataset asli tetap utuh)\n",
        "    )\n",
        "    print(f\"\\nDataset split completed successfully!\")\n",
        "    print(f\"New split dataset is located at: {output_split_path}\")\n",
        "    print(\"You will find 'train', 'val', and 'test' subfolders inside.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError during dataset splitting: {e}\")\n",
        "    print(\"Please check your original_dataset_path and folder structure.\")\n",
        "\n",
        "# ============================================\n",
        "# 5. Konfirmasi Hasil Split (Opsional, untuk memverifikasi)\n",
        "# ============================================\n",
        "print(\"\\n--- Verifying Split Structure and Counts ---\")\n",
        "train_count = 0\n",
        "val_count = 0\n",
        "test_count = 0\n",
        "total_original_count = 0\n",
        "\n",
        "# Dapatkan nama kelas dari folder yang baru dibuat\n",
        "if os.path.exists(os.path.join(output_split_path, 'train')):\n",
        "    class_names = sorted(os.listdir(os.path.join(output_split_path, 'train')))\n",
        "    class_names = [name for name in class_names if os.path.isdir(os.path.join(output_split_path, 'train', name))]\n",
        "else:\n",
        "    print(\"Error: 'train' folder not found in output. Split may have failed.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Classes found: {class_names}\")\n",
        "\n",
        "for class_name in class_names:\n",
        "    train_class_path = os.path.join(output_split_path, 'train', class_name)\n",
        "    val_class_path = os.path.join(output_split_path, 'val', class_name)\n",
        "    test_class_path = os.path.join(output_split_path, 'test', class_name)\n",
        "\n",
        "    train_files = len(os.listdir(train_class_path)) if os.path.exists(train_class_path) else 0\n",
        "    val_files = len(os.listdir(val_class_path)) if os.path.exists(val_class_path) else 0\n",
        "    test_files = len(os.listdir(test_class_path)) if os.path.exists(test_class_path) else 0\n",
        "\n",
        "    print(f\"  {class_name}:\")\n",
        "    print(f\"    Train: {train_files} images\")\n",
        "    print(f\"    Validation: {val_files} images\")\n",
        "    print(f\"    Test: {test_files} images\")\n",
        "\n",
        "    train_count += train_files\n",
        "    val_count += val_files\n",
        "    test_count += test_files\n",
        "\n",
        "# Menghitung total gambar dari dataset asli untuk perbandingan\n",
        "for class_name in class_names:\n",
        "    original_class_path = os.path.join(original_dataset_path, class_name)\n",
        "    if os.path.exists(original_class_path):\n",
        "        total_original_count += len(os.listdir(original_class_path))\n",
        "\n",
        "total_split_count = train_count + val_count + test_count\n",
        "\n",
        "print(f\"\\n--- Overall Split Summary ---\")\n",
        "print(f\"Total images in Original Dataset: {total_original_count}\")\n",
        "print(f\"Total images in Split Dataset (Train + Val + Test): {total_split_count}\")\n",
        "print(f\"Train Set: {train_count} images ({train_count/total_split_count:.1%})\")\n",
        "print(f\"Validation Set: {val_count} images ({val_count/total_split_count:.1%})\")\n",
        "print(f\"Test Set: {test_count} images ({test_count/total_split_count:.1%})\")\n",
        "\n",
        "if total_split_count == total_original_count:\n",
        "    print(\"Verification: Total images in split dataset matches original dataset.\")\n",
        "else:\n",
        "    print(\"Warning: Total images in split dataset does NOT match original dataset. Investigate!\")\n",
        "\n",
        "print(\"\\n--- Dataset Splitting Script Finished ---\")"
      ]
    }
  ]
}